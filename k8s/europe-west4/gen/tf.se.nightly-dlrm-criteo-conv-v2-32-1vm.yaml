# Copyright 2020 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"apiVersion": "batch/v1"
"kind": "CronJob"
"metadata":
  "labels":
    "accelerator": "v2-32"
    "benchmarkId": "tf.se.nightly-dlrm-criteo-conv-v2-32-1vm"
    "frameworkVersion": "tf.se.nightly"
    "mode": "conv"
    "model": "dlrm-criteo"
  "name": "tf.se.nightly-dlrm-criteo-conv-v2-32-1vm"
  "namespace": "automated"
"spec":
  "concurrencyPolicy": "Forbid"
  "jobTemplate":
    "metadata":
      "annotations":
        "ml-testing-accelerators/gcs-subdir": "tf.se.nightly/dlrm-criteo/conv/v2-32"
        "ml-testing-accelerators/metric-config": |
          {
            "sources": [
              {
                "tensorboard": {
                  "aggregate_assertions": [
                    {
                      "assertion": {
                        "inclusive_bounds": true,
                        "std_devs_from_mean": {
                          "comparison": "GREATER",
                          "std_devs": 2
                        },
                        "wait_for_n_data_points": 0
                      },
                      "strategy": "AVERAGE",
                      "tag": "examples_per_second"
                    }
                  ],
                  "exclude_tags": [
          
                  ],
                  "include_tags": [
                    {
                      "strategies": [
                        "FINAL"
                      ],
                      "tag_pattern": "*"
                    }
                  ],
                  "merge_runs": false
                }
              }
            ]
          }
      "labels":
        "accelerator": "v2-32"
        "benchmarkId": "tf.se.nightly-dlrm-criteo-conv-v2-32-1vm"
        "frameworkVersion": "tf.se.nightly"
        "mode": "conv"
        "model": "dlrm-criteo"
    "spec":
      "activeDeadlineSeconds": 86400
      "backoffLimit": 0
      "template":
        "metadata":
          "annotations":
            "reserved.cloud-tpus.google.com": "false"
            "tf-version.cloud-tpus.google.com": "v2-alpha-tpuv5-lite"
        "spec":
          "activeDeadlineSeconds": 36000
          "containers":
          - "args": null
            "command":
            - "bash"
            - "-c"
            - |
              set -x
              set -u
              gcloud alpha compute tpus tpu-vm ssh xl-ml-test@$(cat /scripts/tpu_name) --zone=$(cat /scripts/zone) --ssh-key-file=/scripts/id_rsa --strict-host-key-checking=no --internal-ip --command \
                'pip install -r /usr/share/tpu/models/official/requirements.txt'
              gcloud alpha compute tpus tpu-vm ssh xl-ml-test@$(cat /scripts/tpu_name) --zone=$(cat /scripts/zone) --ssh-key-file=/scripts/id_rsa --strict-host-key-checking=no --internal-ip --command \
                'pip install tensorflow-recommenders --no-deps'
              gcloud alpha compute tpus tpu-vm ssh xl-ml-test@$(cat /scripts/tpu_name) --zone=$(cat /scripts/zone) --ssh-key-file=/scripts/id_rsa --strict-host-key-checking=no --internal-ip --command \
                'pip install --upgrade --force-reinstall tf-keras-nightly'
              gcloud alpha compute tpus tpu-vm ssh xl-ml-test@$(cat /scripts/tpu_name) --zone=$(cat /scripts/zone) --ssh-key-file=/scripts/id_rsa --strict-host-key-checking=no --internal-ip --command \
                'cd /usr/share/tpu/models; PYTHONPATH=${PWD} TF_USE_LEGACY_KERAS=1 TPU_LOAD_LIBRARY=0 WRAPT_DISABLE_EXTENSIONS=true ''"python3" "official/recommendation/ranking/train.py" "--params_override=\"runtime\":
                \"distribution_strategy\": \"tpu\"
                \"tpu\": \"$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\"
              \"task\":
                \"model\":
                  \"bottom_mlp\":
                  - 512
                  - 256
                  - 64
                  \"embedding_dim\": 64
                  \"interaction\": \"dot\"
                  \"num_dense_features\": 13
                  \"top_mlp\":
                  - 1024
                  - 1024
                  - 512
                  - 256
                  - 1
                  \"vocab_sizes\":
                  - 39884406
                  - 39043
                  - 17289
                  - 7420
                  - 20263
                  - 3
                  - 7120
                  - 1543
                  - 63
                  - 38532951
                  - 2953546
                  - 403346
                  - 10
                  - 2208
                  - 11938
                  - 155
                  - 4
                  - 976
                  - 14
                  - 39979771
                  - 25641295
                  - 39664984
                  - 585935
                  - 12972
                  - 108
                  - 36
                \"train_data\":
                  \"global_batch_size\": 16384
                  \"input_path\": \"$(CRITEO_DATA_DIR)/train/*\"
                \"validation_data\":
                  \"global_batch_size\": 16384
                  \"input_path\": \"$(CRITEO_DATA_DIR)/eval/*\"
              \"trainer\":
                \"checkpoint_interval\": 270000
                \"optimizer_config\":
                  \"embedding_optimizer\": \"SGD\"
                  \"lr_config\":
                    \"decay_exp\": 1.6000000000000001
                    \"decay_start_steps\": 150000
                    \"decay_steps\": 136054
                    \"learning_rate\": 30
                    \"warmup_steps\": 8000
                \"train_steps\": 256054
                \"use_orbit\": true
                \"validation_interval\": 90000
                \"validation_steps\": 5440
              " "--model_dir=$(MODEL_DIR)" "--mode=train_and_eval"'
              exit_code=$?
              bash /scripts/cleanup.sh
              exit $exit_code
            "env":
            - "name": "POD_NAME"
              "valueFrom":
                "fieldRef":
                  "fieldPath": "metadata.name"
            - "name": "POD_UID"
              "valueFrom":
                "fieldRef":
                  "fieldPath": "metadata.uid"
            - "name": "POD_NAMESPACE"
              "valueFrom":
                "fieldRef":
                  "fieldPath": "metadata.namespace"
            - "name": "JOB_NAME"
              "valueFrom":
                "fieldRef":
                  "fieldPath": "metadata.labels['job-name']"
            - "name": "MODEL_DIR"
              "value": "$(OUTPUT_BUCKET)/tf.se.nightly/dlrm-criteo/conv/v2-32/$(JOB_NAME)"
            - "name": "KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS"
              "value": "tpu-$(POD_UID)"
            - "name": "LOCAL_OUTPUT_DIR"
              "value": "/tmp/model_dir"
            - "name": "TF_ENABLE_LEGACY_FILESYSTEM"
              "value": "1"
            "envFrom":
            - "configMapRef":
                "name": "gcs-buckets"
            "image": "google/cloud-sdk"
            "imagePullPolicy": "Always"
            "lifecycle":
              "preStop":
                "exec":
                  "command":
                  - "bash"
                  - "/scripts/cleanup.sh"
            "name": "train"
            "resources":
              "limits":
                "tpu.googleapis.com/v2": 32
              "requests":
                "cpu": 1
                "memory": "2Gi"
            "volumeMounts":
            - "mountPath": "/scripts"
              "name": "scripts"
              "readOnly": false
            - "mountPath": "/dev/shm"
              "name": "dshm"
              "readOnly": false
          "initContainers":
          - "command":
            - "/bin/bash"
            - "-c"
            - |
              set -u
              set -e
              set -x
              
              project=$(curl -sS "http://metadata.google.internal/computeMetadata/v1/project/project-id" -H "Metadata-Flavor: Google")
              zone=$(curl -sS "http://metadata.google.internal/computeMetadata/v1/instance/zone" -H "Metadata-Flavor: Google" | awk -F'/' '{print $4}')
              tpu_name=tpu-${POD_UID}
              ssh-keygen -t rsa -f /scripts/id_rsa -q -N ""
              
              echo "
              gcloud alpha compute tpus tpu-vm delete -q --async ${tpu_name} --zone=${zone}
              sleep 60
              " > /scripts/cleanup.sh
              
              echo "xl-ml-test:$(cat /scripts/id_rsa.pub)" > ssh-keys.txt
              echo 'echo Running startup script' > startup-script.txt
              
              # Retry every 30 seconds for up to 10 minutes
              start_time="$(date -u +%s)"
              for i in {1..20}; do
                set +e
                gcloud alpha compute tpus tpu-vm create ${tpu_name} \
                  --accelerator-type='v2-32' \
                  --version='v2-alpha-tpuv5-lite'  \
                  --metadata-from-file='ssh-keys=ssh-keys.txt,startup-script=startup-script.txt' \
                  --labels='test-name=tf-se-nightly-dlrm-criteo-conv-v2-32-1vm' \
                  --zone=${zone}
              
                exit_code=$?
                set -e
              
                current_time="$(date -u +%s)"
                elapsed_seconds=$(($current_time-$start_time))
                # Break if command passed or 10-minute limit reached
                test $exit_code = 0 && break
                test $elapsed_seconds -gt 600 && break
                sleep 30
              done
              
              if [ $exit_code -ne 0 ]; then
                exit $exit_code
              fi 
              echo ${zone} > /scripts/zone
              echo ${tpu_name} > /scripts/tpu_name
              gcloud compute tpus describe ${tpu_name} --project=${project} --zone=${zone} --format="value(networkEndpoints[0].ipAddress)" > /scripts/tpu_ip
              gcloud compute tpus describe ${tpu_name} --project=${project} --zone=${zone} --flatten="networkEndpoints[]" --format="csv[no-heading](networkEndpoints.ipAddress)" > /scripts/all_tpu_ips
              sleep 60
              
              gcloud alpha compute tpus tpu-vm ssh ${tpu_name}  --zone=${zone} --project=${project}  --internal-ip --ssh-key-file=/scripts/id_rsa --worker=0 --command "pip install tensorflow-text-nightly"
              gcloud alpha compute tpus tpu-vm ssh ${tpu_name}  --zone=${zone} --project=${project}  --internal-ip --ssh-key-file=/scripts/id_rsa --worker=0 --command "gsutil -m cp gs://cloud-tpu-v2-images-dev-artifacts/tensorflow/tf-nightly/latest/*.whl /tmp/ && pip install /tmp/tf*.whl --force"
              
              gcloud alpha compute tpus tpu-vm ssh ${tpu_name}  --zone=${zone} --project=${project}  --internal-ip --ssh-key-file=/scripts/id_rsa --worker=all --command "sudo gsutil -m cp gs://cloud-tpu-v2-images-dev-artifacts/libtpu/latest/libtpu.so /lib/"
              gcloud alpha compute tpus tpu-vm ssh ${tpu_name}  --zone=${zone} --project=${project}  --internal-ip --ssh-key-file=/scripts/id_rsa --worker=0 --command "sudo mkdir -p /usr/share/tpu && cd /usr/share/tpu && git clone https://github.com/tensorflow/models.git"
              
              accelerator_type='v2-32'
              if (( ${accelerator_type: -2} > 8 )); then
                gcloud alpha compute tpus tpu-vm ssh ${tpu_name}  --zone=${zone} --project=${project}  --internal-ip --ssh-key-file=/scripts/id_rsa --worker=all --command "sudo sed -i 's/TF_DOCKER_URL=.*/TF_DOCKER_URL=gcr.io\/cloud-tpu-v2-images-dev\/grpc_tpu_worker:nightly\"/' /etc/systemd/system/tpu-runtime.service"
                gcloud alpha compute tpus tpu-vm ssh ${tpu_name}  --zone=${zone} --project=${project}  --internal-ip --ssh-key-file=/scripts/id_rsa --worker=all --command "sudo systemctl daemon-reload && sudo systemctl restart tpu-runtime"
              fi
              
            "env":
            - "name": "POD_UID"
              "valueFrom":
                "fieldRef":
                  "fieldPath": "metadata.uid"
            "image": "google/cloud-sdk"
            "name": "create-tpu"
            "volumeMounts":
            - "mountPath": "/scripts"
              "name": "scripts"
          - "command": null
            "image": "google/cloud-sdk"
            "name": "tpu-version"
          "nodeSelector":
            "tpu-available": "true"
          "priorityClassName": "tpu-pod"
          "restartPolicy": "Never"
          "volumes":
          - "emptyDir":
              "medium": "Memory"
            "name": "scripts"
          - "emptyDir":
              "medium": "Memory"
            "name": "dshm"
  "schedule": "0 5 * * 0,2,4"
  "successfulJobsHistoryLimit": 1
  "suspend": false